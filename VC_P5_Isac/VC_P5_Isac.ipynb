{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5 - Isac Añor Santana\n",
    "\n",
    "Reconocimiento de matrículas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes necesarios\n",
    "Adicionalmente, es necesario agregar los siguiente paquetes al entorno virtual:\n",
    "\n",
    "`pip install imutils`\n",
    "\n",
    "`pip install scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import imutils\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la clase de reconocimiento de matrículas y funciones auxiliares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ALPR (Automatic License Plate Recognition)\n",
    "Esta clase se encarga del reconocimiento de la matrícula y la extracción de su texto usando el motor de Tesseract.\n",
    "\n",
    "El reconocimiento de la matrícula se hace en dos fases:\n",
    "1. En la primera fase se buscan candidatos a ser matrículas con el siguiente algoritmo:\n",
    "    - En primer lugar, se hace una transformación morfológica de \"sombrero negro\" o Black Hat, resultado de la diferencia entre el cerrado de la imagen y la imagen original. La finalidad simplificar la detección asumiendo que las matrículas generalmente están constituidas por un fondo claro y un primer plano oscuro (los caracteres). La aplicacón de esta transformación morfológica revelará los caracteres negros sobre un fondo claro.\n",
    "    - En segundo lugar, se aplica una operación de cerrado para llenar pequeños agujeros e identificar estructuras más grandes en la imagen. Estas estructuras se usarán más adelante.\n",
    "    - Se aplica el gradiente de Scharr a la imagen resultante de la transformación morforlógica de Black Hat, con la finalidad de detectar los bordes en la imagen y especialmente remarcar los límites de los caracteres de la matrícula.\n",
    "    - Se prosigue con un desenfoque Gaussiano para suavizar la imagen y agrupar las regiones que puedan contener los límites de los caracteres de la matrícula.\n",
    "    - Se realiza una operación de erosion y dilatación para reducir el ruido.\n",
    "    - Finalmente se realiza una comparación lógica de AND bit a bit usando la imagen de estructuras como máscara, seguido de una dilatación y una erosión para reducir el ruido.\n",
    "    - De esta imagen resultante se extraen los contornos de mayor tamaño.\n",
    "\n",
    "2. En la segunda fase, de entre los candidatos, se hace un filtrado por relación de aspecto y se devuelve tanto el recorte de la imagen como el contorno. Se asume que aquellos contornos con la relación de aspecto propuesta son matrículas.\n",
    "\n",
    "Finalmente, los contornos seleccionados se pasan por el \"reconocedor óptico de caracteres\" Tesseract. Si reconoce algo, se muestra el contorno en la imagen con lo que ha reconocido.\n",
    "\n",
    "\n",
    "Entre varias fuentes de internet, se destaca el uso de:\n",
    "\n",
    "https://pyimagesearch.com/2020/09/21/opencv-automatic-license-number-plate-recognition-anpr-with-python/\n",
    "\n",
    "https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html \n",
    "\n",
    "https://iopscience.iop.org/article/10.1088/1742-6596/806/1/012004/pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomaticLicensePlateRecognition:\n",
    "    def __init__(self, minAspectRatio = 4, maxAspectRatio = 6, debug = False):\n",
    "        \"\"\"\n",
    "        Will initialize the minimum and maximum aspect ratios.\n",
    "        Also whether or not debug mode is present.\n",
    "\n",
    "        :param int minAspectRatio: Minimum aspect ratio\n",
    "        :param int maxAspectRatio: Maximum aspect ratio\n",
    "        :param bool debug: Whether or not in debug mode\n",
    "        \"\"\"\n",
    "        self.minAspectRatio = minAspectRatio\n",
    "        self.maxAspectRatio = maxAspectRatio\n",
    "        self.debug = debug\n",
    "\n",
    "    def concatenate_horizontally(self, image1, image2):\n",
    "        \"\"\"\n",
    "        Will concatenate two images horizontally\n",
    "\n",
    "        :param image image1: Image 1\n",
    "        :param image image2: Image 2\n",
    "        \"\"\"\n",
    "        return np.concatenate((image1, image2), axis = 1)\n",
    "\n",
    "    def concatenate_vertically(self, image1, image2):\n",
    "        \"\"\"\n",
    "        Will concatenate two images vertically\n",
    "\n",
    "        :param image image1: Image 1\n",
    "        :param image image2: Image 2\n",
    "        \"\"\"\n",
    "        return np.concatenate((image1, image2), axis = 0)\n",
    "    \n",
    "    def debug_imshow(self, title, img, waitKey = False):\n",
    "        \"\"\"\n",
    "        Will show the image in case of being in debug mode.\n",
    "\n",
    "        :param str title: Title of the frame created by imshow\n",
    "        :param image img: Image to display\n",
    "        :param bool waitKey: Flag to see if the display should wait for a keyboard press\n",
    "        \"\"\"\n",
    "        if self.debug:\n",
    "            cv2.imshow(title, img)\n",
    "            # check to see if we should wait for a keypress\n",
    "            if waitKey:\n",
    "                cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def locate_license_plate_candidates(self, gray, keep=40):\n",
    "        \"\"\"\n",
    "        Wilkl perform a blackhat morphological operation that will reveal dark regions (i.e., text) on light backgrounds.\n",
    "        Morphological transformations tutorial:\n",
    "        https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html\n",
    "\n",
    "        :param image gray: Grayscale image containing a potential license plate\n",
    "        :param int keep: Maximum sorted license plate contours to return\n",
    "        :return: Candidate license plate contours\n",
    "        :rtype: List\n",
    "        \"\"\"\n",
    "        # Blackhat morphological operation\n",
    "        rectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "        blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKern)\n",
    "        if self.debug:\n",
    "            blackhat_debug = blackhat.copy()\n",
    "            cv2.putText(blackhat_debug, \"Black Hat\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "        \n",
    "        # Find regions that are light and may contain license plate characters.\n",
    "        squareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        light = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, squareKern)\n",
    "        light = cv2.threshold(light, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        if self.debug:\n",
    "            light_debug = light.copy()\n",
    "            cv2.putText(light_debug, \"Light Regions\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "        # Compute the Scharr gradient representation of the blackhat image in the x-direction and then scale the result back to the range [0, 255]\n",
    "        gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "        gradX = np.absolute(gradX)\n",
    "        (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "        gradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
    "        gradX = gradX.astype(\"uint8\")\n",
    "        if self.debug:\n",
    "            scharr_debug = gradX.copy()\n",
    "            cv2.putText(scharr_debug, \"Scharr\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "        # Blur the gradient representation, applying a closing operation, and threshold the image using Otsu's method\n",
    "        gradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
    "        gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
    "        thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        if self.debug:\n",
    "            grad_thresh_debug = thresh.copy()\n",
    "            cv2.putText(grad_thresh_debug, \"GaussianBlur\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "        # Perform a series of erosions and dilations to eliminate noise to the thresholded image\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        if self.debug:\n",
    "            grad_thresh_noise_reduction_debug = thresh.copy()\n",
    "            cv2.putText(grad_thresh_noise_reduction_debug, \"Erode_Dilate\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "        # Take the bitwise AND between the threshold result and the\tlight regions of the image\n",
    "        thresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        thresh = cv2.erode(thresh, None, iterations=1)\n",
    "        if self.debug:\n",
    "            bitwise_debug = thresh.copy()\n",
    "            cv2.putText(bitwise_debug, \"Bitwise Dilate Erode\", (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "            top_debug_image = self.concatenate_horizontally(blackhat_debug, light_debug)\n",
    "            top_debug_image = self.concatenate_horizontally(top_debug_image, scharr_debug)\n",
    "            bottom_debug_image = self.concatenate_horizontally(grad_thresh_debug, grad_thresh_noise_reduction_debug)\n",
    "            bottom_debug_image = self.concatenate_horizontally(bottom_debug_image, bitwise_debug)\n",
    "            final_debug_image = self.concatenate_vertically(top_debug_image, bottom_debug_image)\n",
    "            self.debug_imshow(\"Final Debug Image\", final_debug_image, waitKey=True)\n",
    "\n",
    "        # Find contours in the thresholded image and sort them by their size in descending order, keeping only the largest ones\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:keep]\n",
    "        return cnts\n",
    "\n",
    "\n",
    "    def locate_license_plate(self, gray, candidates, clearBorder=False):\n",
    "        \"\"\"\n",
    "        Method that will find the most likely contour containing a license plate out of the set of candidates.\n",
    "\n",
    "        :param image gray: Input grayscale image\n",
    "        :param list candidates: License plate candidates returned by locate_license_plate_candidates\n",
    "        :param bool clearBorder: Whether contours at the edge of the image should be eliminated\n",
    "        :return: List with license plates' region of interest and contour\n",
    "        :rtype: List\n",
    "        \"\"\"\n",
    "        # Initialize the license plate contour and Region Of Interest\n",
    "        licensePlateContour = None\n",
    "        regionOfInterest = None\n",
    "\n",
    "        selected_contours = []\n",
    "        for candidateContour in candidates:\n",
    "            # Candidate aspect ratio calculation\n",
    "            (x, y, w, h) = cv2.boundingRect(candidateContour)\n",
    "            ar = w / float(h)\n",
    "            # Verify aspect ratio\n",
    "            if ar >= self.minAspectRatio and ar <= self.maxAspectRatio:\n",
    "                # Store the license plate contour and extract the license plate from the grayscale image and then threshold it\n",
    "                licensePlateContour = candidateContour\n",
    "                licensePlate = gray[y:y + h, x:x + w]\n",
    "                regionOfInterest = cv2.threshold(licensePlate, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "                \n",
    "                # Check to see if we should clear any foreground pixels touching the border of the image\n",
    "                # (which typically, not but always, indicates noise)\n",
    "                if clearBorder:\n",
    "                    regionOfInterest = clear_border(regionOfInterest)\n",
    "                \n",
    "                # Display any debugging information and then break\n",
    "                if self.debug:\n",
    "                    final_debug_image = self.concatenate_horizontally(licensePlate, regionOfInterest)\n",
    "                    self.debug_imshow(\"Extracted License Plate\", final_debug_image, waitKey=True)\n",
    "                selected_contours.append((regionOfInterest, licensePlateContour))\n",
    "        \n",
    "        return selected_contours\n",
    "\n",
    "    def build_tesseract_options(self, psm=7):\n",
    "        \"\"\"\n",
    "        Will build the Tessereact config input parameter.\n",
    "\n",
    "        :param int psm: Page Segmentation Method. There are 13 modes of operation. \n",
    "        7 is used by default: \"treat the image as a single text line\"\n",
    "        \"\"\"\n",
    "        # Only recognize alphanumeric characters\n",
    "        alphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "        options = f\"-c tessedit_char_whitelist={alphanumeric}\"\n",
    "        # Set the PSM mode\n",
    "        options += \" --psm {}\".format(psm)\n",
    "        return options\n",
    "\n",
    "    def find_and_ocr(self, image, psm=7, clearBorder=False):\n",
    "        \"\"\"\n",
    "        Will proceed to find license plates and perform an optical character recognition.\n",
    "\n",
    "        :param image image: Three-channel color image of car with license plate\n",
    "        :param int psm: Tesseract Page Segmentation Mode\n",
    "        :param bool clearBorder: Whether contours at the edge of the image should be eliminated\n",
    "        :return: License plate detected text and it's contour\n",
    "        :rtype: 2-tuple (str, contour)\n",
    "        \"\"\"\n",
    "        # Pnitialize the license plate text\n",
    "        licensePlateText = None\n",
    "        # Convert the input image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Locate candidate plates\n",
    "        candidates = self.locate_license_plate_candidates(gray)\n",
    "        # Locate matching license plate\n",
    "        selected_contours = self.locate_license_plate(gray, candidates, clearBorder=clearBorder)\n",
    "        # Only perform the OCR if the license plate ROI is not empty\n",
    "        text_and_contours = []\n",
    "        if len(selected_contours) > 0:\n",
    "            for licensePlate, licensePlateContour in selected_contours:\n",
    "                # OCR the license plate\n",
    "                options = self.build_tesseract_options(psm=psm)\n",
    "                licensePlateText = pytesseract.image_to_string(licensePlate, config=options)\n",
    "                self.debug_imshow(\"License Plate\", licensePlate)\n",
    "                text_and_contours.append((licensePlateText, licensePlateContour))\n",
    "        \n",
    "        return text_and_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion auxiliar para filtrar caracteres que no seas ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "\t# strip out non-ASCII text so we can draw the text on the image\n",
    "\treturn \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función auxiliar para calcular como de buena ha sido la detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predicted_accuracy(actual_plate, predicted_plate):\n",
    "    accuracy = \"0 %\"\n",
    "    num_matches = 0\n",
    "    if actual_plate == predicted_plate:\n",
    "        accuracy = \"100 %\"\n",
    "    else:\n",
    "        if len(actual_plate) == len(predicted_plate):\n",
    "            for a, p in zip(actual_plate, predicted_plate):\n",
    "                if a == p:\n",
    "                    num_matches += 1\n",
    "            accuracy = str(round((num_matches / len(actual_plate)), 2) * 100)\n",
    "            accuracy += \"%\"\n",
    "    \n",
    "    print(f\"{actual_plate.ljust(24)}{predicted_plate.ljust(27)}{accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recorrido y resultados\n",
    "Se recorre un conjunto de imagenes de matrículas seleccionado. Para cada imagen, si detecta algo, muestra la imagen con el contorno seleccionado que cree que es una matrícula. En caso contrario, no muestra nada. Adicionalmente, en caso de detectar una matrícula, compara ambas ristras y devuelve un porcentaje de los caracteres detectados que están colocados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual License Plate    Predicted License Plate    Accuracy\n",
      "--------------------    -----------------------    --------\n",
      "0802HFP                 None                       0 %\n",
      "1159FPG                 BISSFP                     0 %\n",
      "1319FSX                 None                       0 %\n",
      "2522LNH                 None                       0 %\n",
      "2711LKN                 None                       0 %\n",
      "2942HFB                 PS42HFE                    56.99999999999999%\n",
      "3838KWB                 3838KWB                    100 %\n",
      "4078BVX                 None                       0 %\n",
      "4841LFS                 4841LFS                    100 %\n",
      "4950KZK                 4950K7K                    86.0%\n",
      "5239LSB                 None                       0 %\n",
      "5921LMH                 None                       0 %\n",
      "6298KSN                 None                       0 %\n",
      "6299JJL                 6299JF                     0 %\n",
      "7270GVF                 None                       0 %\n",
      "8168GJG                 8168GJG                    100 %\n",
      "8712HJG                 8712HJG                    100 %\n",
      "8903KPT                 None                       0 %\n",
      "CNP2309AW               BCNP2309A8                 0 %\n",
      "GC4370BV                None                       0 %\n",
      "GR5101AT                None                       0 %\n"
     ]
    }
   ],
   "source": [
    "# Path to Tesseract engine\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Instance of the recognition class\n",
    "#automaticLicensePlateRecognition = AutomaticLicensePlateRecognition(debug=True)\n",
    "automaticLicensePlateRecognition = AutomaticLicensePlateRecognition()\n",
    "\n",
    "path_for_license_plates = os.getcwd() + \"./license_plates/**/*.jpg\"\n",
    "\n",
    "print(f\"Actual License Plate    Predicted License Plate    Accuracy\")\n",
    "print(f\"--------------------    -----------------------    --------\")\n",
    "\n",
    "# Iterate over the license plates\n",
    "for path_to_license_plate in glob.glob(path_for_license_plates, recursive=True):\n",
    "    # Get license plates\n",
    "    # Linux\n",
    "    #license_plate_file = path_to_license_plate.split(\"/\")[-1]\n",
    "    # Windows\n",
    "    license_plate_file = path_to_license_plate.split(\"\\\\\")[-1]\n",
    "    license_plate, _ = os.path.splitext(license_plate_file)\n",
    "\n",
    "    # Image read\n",
    "    img = cv2.imread(path_to_license_plate)\n",
    "    # Resize with imutils (used to have images that fit in the monitor when debugging)\n",
    "    img = imutils.resize(img, width=400)\n",
    "\n",
    "    #text_and_contours = automaticLicensePlateRecognition.find_and_ocr(img)\n",
    "    # Depending on the clear border (strop foreground pixels that touch border of the image) we can get different results\n",
    "    text_and_contours = automaticLicensePlateRecognition.find_and_ocr(img, clearBorder=True)\n",
    "    \n",
    "    if len(text_and_contours) > 0:\n",
    "        for licensePlateText, licensePlateContour in text_and_contours:\n",
    "            # Fit a rotated bounding box to the license plate contour and draw the bounding box on the license plate\n",
    "            box = cv2.boxPoints(cv2.minAreaRect(licensePlateContour))\n",
    "            box = box.astype(\"int\")\n",
    "            cv2.drawContours(img, [box], -1, (0, 255, 0), 2)\n",
    "            # Add text on the image\n",
    "            (x, y, w, h) = cv2.boundingRect(licensePlateContour)\n",
    "            cv2.putText(img, cleanup_text(licensePlateText), (x, y - 15),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "            calculate_predicted_accuracy(license_plate, cleanup_text(licensePlateText))\n",
    "            cv2.imshow(\"Output ALPR\", img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    else: \n",
    "        calculate_predicted_accuracy(license_plate, \"None\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d52ac33933a74f17cb83a3a0d56e2068f2eb6c4aeae2206b8911f77f204fd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
